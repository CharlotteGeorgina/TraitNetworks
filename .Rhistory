ifelse(V(TGraph)$name == "R_Nesters", "coral4",
ifelse(V(TGraph)$name == "R_Scatterers", "violetred2",
ifelse(V(TGraph)$name == "R_Demersal", "violetred4","red"))))))))))))))))))))))))))))
#Assign group ideas = modules
group_ids <- lapply(tModule %>% split(.$tModule), function(grp) { grp$ID })
group_ids
# set colour
group_colour <- c("gray", "gray", "gray", "gray", "gray")
#same but add transparency
group_colour_fill <- paste0(group_colour, '95')
#set node sizes
V(TGraph)$size<-t_metrix$t_Degree*100
#specify layout
layout = layout_with_kk(TGraph)
##to save plot
pdf(file=paste0("Results/Graphs/",Cluster,".pdf"))
plot(TGraph,
edge.width=2,
edge.color="black",
vertex.label.color="black",
Vertex.label.dist = 3,
#vertex.label.degree = pi/4,
mark.groups = group_ids,
mark.col = group_colour_fill,
mark.border = group_colour,
layout = layout, hovermode='closest')
dev.off()
}
#save the Cooccurs and Metrix from the entire loop
write.csv(Reg_metrix, 'Results/JPFish_TropTemp_Reg_metrix_13/06/24.csv')
#save the Cooccurs and Metrix from the entire loop
write.csv(Reg_metrix, 'Results/JPFish_TropTemp_Reg_metrix_13/06/24.csv')
View(Reg_metrix)
#save the Cooccurs and Metrix from the entire loop
write.csv(Reg_metrix, 'Results/JPFish_TropTemp_Reg_metrix_13_06_24.csv')
#### Data ####
CWM <- read.csv("Data/CWM_JPFish_Biomass_TropTemp.csv")
CWM <- CWM %>% rename(Site = X)
#organise and rename
CWM <- CWM %>% relocate(Cluster, .before = Site)
CWM <- CWM %>% column_to_rownames(., var = 'Site')
colnames(CWM) <- c("Cluster", "ML_Large", "ML_Medium", "ML_Small",
"ML_V.Small", "PLD_Long", "PLD_Medium", "PLD_Short",
"PLD_V.Long", "T_Corrallivore", "T_Detritivore",
"T_Herbivore", "T_Omnivore", "T_Piscivore",
"T_Planktivore", "T_Predator", "P_Benthic",
"P_AnthozoanA", "P_Demersal",
"P_Pelagic", "P_ReefPelagic", "P_SandA", "P_SubBenthic",
"P_UpperBenthic", "R_Brooders", "R_Demersal",
"R_livebearers", "R_Nesters", "R_Scatterers")
##### Make a counter file for regions for looping:  ----
countR <- data.frame(Cluster = c("Tropical", "Temperate"))
# Initialize the result data frame
all_metrics <- list()
bootstrap_iterations <- 1000
Cluster <- countR[1, 1]
CWM_i <- CWM[CWM$Cluster == Cluster,] %>% select(-Cluster)
View(CWM_i)
# Initialize data frames to store bootstrap results
bootstrap_metrics <- data.frame(DegCents=numeric(), BetwCentr=numeric(), EigCentr=numeric(), EdgeDen=numeric(), NoModule=numeric(), NetModularity=numeric())
for (j in 1:bootstrap_iterations) {
# Bootstrapping
CWM_bootstrap <- CWM_i[sample(nrow(CWM_i), replace = TRUE), ]
# Calculate correlation matrix and significance
CWM_Cor <- rcorr(as.matrix(CWM_bootstrap))
CWM_prob <- ifelse(CWM_Cor$P < 0.05, 1, 0)
CWM_eff <- CWM_Cor$r
SignMatrix <- CWM_prob * CWM_eff
SignMatrix[is.na(SignMatrix)] <- 0
SignMatrix <- ifelse(SignMatrix > 0.1, 1, 0)
SignMatrix2 <- SignMatrix[rowSums(SignMatrix == 0) != ncol(SignMatrix), colSums(SignMatrix == 0) != nrow(SignMatrix)]
# Generate network graph
TGraph <- graph_from_adjacency_matrix(SignMatrix2, mode = "undirected")
WT_partition <- cluster_walktrap(TGraph, weights = NULL)
# Calculate network-wide metrics
DegCents <- centr_clo(TGraph, mode = "all")$centralization
BetwCentr <- centr_betw(TGraph, directed = FALSE)$centralization
EigCentr <- centr_eigen(TGraph, directed = FALSE)$centralization
EdgeDen <- edge_density(TGraph, loops = FALSE)
NoModule <- length(WT_partition)
NetModularity <- modularity(TGraph, membership(WT_partition))
# Store metrics
bootstrap_metrics[j, ] <- c(DegCents, BetwCentr, EigCentr, EdgeDen, NoModule, NetModularity)
}
# Store all bootstrap metrics for the current cluster
all_metrics[[Cluster]] <- bootstrap_metrics
View(bootstrap_metrics)
View(countR)
View(TGraph)
View(all_metrics)
##### Make a counter file for regions for looping:  ----
countR <- data.frame(Cluster = c("Tropical", "Temperate"))
# Initialize the result data frame
all_metrics <- list()
bootstrap_iterations <- 1000
# Bootstrapping and network metric calculation
for (i in 1:nrow(countR)) {
Cluster <- countR[i, 1]
CWM_i <- CWM[CWM$Cluster == Cluster,] %>% select(-Cluster)
# Initialize data frames to store bootstrap results
bootstrap_metrics <- data.frame(DegCents=numeric(), BetwCentr=numeric(), EigCentr=numeric(), EdgeDen=numeric(), NoModule=numeric(), NetModularity=numeric())
for (j in 1:bootstrap_iterations) {
# Bootstrapping
CWM_bootstrap <- CWM_i[sample(nrow(CWM_i), replace = TRUE), ]
# Calculate correlation matrix and significance
CWM_Cor <- rcorr(as.matrix(CWM_bootstrap))
CWM_prob <- ifelse(CWM_Cor$P < 0.05, 1, 0)
CWM_eff <- CWM_Cor$r
SignMatrix <- CWM_prob * CWM_eff
SignMatrix[is.na(SignMatrix)] <- 0
SignMatrix <- ifelse(SignMatrix > 0.1, 1, 0)
SignMatrix2 <- SignMatrix[rowSums(SignMatrix == 0) != ncol(SignMatrix), colSums(SignMatrix == 0) != nrow(SignMatrix)]
# Generate network graph
TGraph <- graph_from_adjacency_matrix(SignMatrix2, mode = "undirected")
WT_partition <- cluster_walktrap(TGraph, weights = NULL)
# Calculate network-wide metrics
DegCents <- centr_clo(TGraph, mode = "all")$centralization
BetwCentr <- centr_betw(TGraph, directed = FALSE)$centralization
EigCentr <- centr_eigen(TGraph, directed = FALSE)$centralization
EdgeDen <- edge_density(TGraph, loops = FALSE)
NoModule <- length(WT_partition)
NetModularity <- modularity(TGraph, membership(WT_partition))
# Store metrics
bootstrap_metrics[j, ] <- c(DegCents, BetwCentr, EigCentr, EdgeDen, NoModule, NetModularity)
}
# Store all bootstrap metrics for the current cluster
all_metrics[[Cluster]] <- bootstrap_metrics
}
View(all_metrics)
# Calculate mean and standard deviation for each region and metric
mean_sd_metrics <- data.frame()
for (cluster in names(all_metrics)) {
cluster_metrics <- all_metrics[[cluster]]
means <- colMeans(cluster_metrics)
sds <- apply(cluster_metrics, 2, sd)
mean_sd_metrics <- rbind(mean_sd_metrics, cbind(Cluster=cluster, t(means), t(sds)))
}
colnames(mean_sd_metrics) <- c("Cluster", "Mean_DegCents", "Mean_BetwCentr", "Mean_EigCentr", "Mean_EdgeDen", "Mean_NoModule", "Mean_NetModularity", "SD_DegCents", "SD_BetwCentr", "SD_EigCentr", "SD_EdgeDen", "SD_NoModule", "SD_NetModularity")
View(mean_sd_metrics)
# Save mean and SD results
write.csv(mean_sd_metrics, 'Results/JPFish_Mean_SD_23_06_24.csv')
# Perform t-tests between tropical and temperate groups for each metric
t_test_results <- data.frame(Metric=character(), p_value=numeric(), stringsAsFactors=FALSE)
metrics <- colnames(all_metrics[[1]])
for (metric in metrics) {
tropical_values <- all_metrics[["Tropical"]][[metric]]
temperate_values <- all_metrics[["Temperate"]][[metric]]
t_test <- t.test(tropical_values, temperate_values)
t_test_results <- rbind(t_test_results, data.frame(Metric=metric, p_value=t_test$p.value))
}
View(t_test_results)
# Perform t-tests between tropical and temperate groups for each metric
t_test_results <- data.frame(Metric=character(), t_stat=numeric(), df=numeric(), p_value=numeric(), stringsAsFactors=FALSE)
metrics <- colnames(all_metrics[[1]])
for (metric in metrics) {
tropical_values <- all_metrics[["Tropical"]][[metric]]
temperate_values <- all_metrics[["Temperate"]][[metric]]
t_test <- t.test(tropical_values, temperate_values)
t_test_results <- rbind(t_test_results, data.frame(Metric=metric, t_stat=t_test$statistic, df=t_test$parameter, p_value=t_test$p.value))
}
# Print the results
print(t_test_results)
View(t_test)
# Perform t-tests between tropical and temperate groups for each metric
t_test_results <- data.frame(Metric=character(), t_stat=numeric(), df=numeric(), p_value=numeric(), stringsAsFactors=FALSE)
metrics <- colnames(all_metrics[[1]])
for (metric in metrics) {
tropical_values <- all_metrics[["Tropical"]][[metric]]
temperate_values <- all_metrics[["Temperate"]][[metric]]
t_test <- t.test(tropical_values, temperate_values, paired = FALSE)
t_test_results <- rbind(t_test_results, data.frame(Metric=metric, t_stat=t_test$statistic, df=t_test$parameter, p_value=t_test$p.value))
}
View(t_test_results)
View(all_metrics)
all_metrics[["Tropical"]][["DegCents"]]
# Perform Shapiro-Wilk test for normality and t-tests or Mann-Whitney U tests based on normality
test_results <- data.frame(Metric=character(), Normality_tropical_p=numeric(), Normality_temperate_p=numeric(), Test=character(), t_stat=numeric(), df=numeric(), W=numeric(), p_value=numeric(), stringsAsFactors=FALSE)
metrics <- colnames(all_metrics[[1]])
for (metric in metrics) {
tropical_values <- all_metrics[["Tropical"]][[metric]]
temperate_values <- all_metrics[["Temperate"]][[metric]]
# Shapiro-Wilk test for normality
shapiro_tropical <- shapiro.test(tropical_values)
shapiro_temperate <- shapiro.test(temperate_values)
if (shapiro_tropical$p.value > 0.05 && shapiro_temperate$p.value > 0.05) {
# Both groups are normally distributed, perform t-test
t_test <- t.test(tropical_values, temperate_values, paired = FALSE)
test_results <- rbind(test_results, data.frame(Metric=metric,
Normality_tropical_p=shapiro_tropical$p.value,
Normality_temperate_p=shapiro_temperate$p.value,
Test="t-test",
t_stat=t_test$statistic,
df=t_test$parameter,
W=NA,
p_value=t_test$p.value))
} else {
# At least one group is not normally distributed, perform Mann-Whitney U test
wilcox_test <- wilcox.test(tropical_values, temperate_values)
test_results <- rbind(test_results, data.frame(Metric=metric,
Normality_tropical_p=shapiro_tropical$p.value,
Normality_temperate_p=shapiro_temperate$p.value,
Test="Mann-Whitney U",
t_stat=NA,
df=NA,
W=wilcox_test$statistic,
p_value=wilcox_test$p.value))
}
}
# Print the results
print(test_results)
View(test_results)
# Perform Shapiro-Wilk test for normality and t-tests or Mann-Whitney U tests based on normality
test_results <- data.frame(Metric=character(), Normality_tropical_p=numeric(), Normality_temperate_p=numeric(), Test=character(), t_stat=numeric(), df=numeric(), W=numeric(), p_value=numeric(), stringsAsFactors=FALSE)
metrics <- colnames(all_metrics[[1]])
format_p_value <- function(p) {
if (p < 0.001) {
return("0.001")
} else if (p < 0.01) {
return("0.01")
} else if (p < 0.05) {
return("0.05")
} else {
return("non-sig")
}
}
for (metric in metrics) {
tropical_values <- all_metrics[["Tropical"]][[metric]]
temperate_values <- all_metrics[["Temperate"]][[metric]]
# Shapiro-Wilk test for normality
shapiro_tropical <- shapiro.test(tropical_values)
shapiro_temperate <- shapiro.test(temperate_values)
if (shapiro_tropical$p.value > 0.05 && shapiro_temperate$p.value > 0.05) {
# Both groups are normally distributed, perform t-test
t_test <- t.test(tropical_values, temperate_values, paired = FALSE)
formatted_p_value <- format_p_value(t_test$p.value)
test_results <- rbind(test_results, data.frame(Metric=metric,
Normality_tropical_p=shapiro_tropical$p.value,
Normality_temperate_p=shapiro_temperate$p.value,
Test="t-test",
t_stat=t_test$statistic,
df=t_test$parameter,
W=NA,
p_value=formatted_p_value))
} else {
# At least one group is not normally distributed, perform Mann-Whitney U test
wilcox_test <- wilcox.test(tropical_values, temperate_values)
formatted_p_value <- format_p_value(t_test$p.value)
test_results <- rbind(test_results, data.frame(Metric=metric,
Normality_tropical_p=shapiro_tropical$p.value,
Normality_temperate_p=shapiro_temperate$p.value,
Test="Mann-Whitney U",
t_stat=NA,
df=NA,
W=wilcox_test$statistic,
p_value=formatted_p_value))
}
}
# Print the results
print(test_results)
View(CWM_bootstrap)
View(bootstrap_metrics)
View(all_metrics)
# Calculate median and interquartile ranges for each region and metric
median_iqr_metrics <- data.frame()
for (cluster in names(all_metrics)) {
cluster_metrics <- all_metrics[[cluster]]
medians <- apply(cluster_metrics, 2, median)
iqr_ranges <- apply(cluster_metrics, 2, IQR)
median_iqr_metrics <- rbind(median_iqr_metrics, cbind(Cluster=cluster, t(medians), t(iqr_ranges)))
}
# Name the columns appropriately
colnames(median_iqr_metrics) <- c("Cluster", "Median_DegCents", "Median_BetwCentr", "Median_EigCentr", "Median_EdgeDen", "Median_NoModule", "Median_NetModularity",
"IQR_DegCents", "IQR_BetwCentr", "IQR_EigCentr", "IQR_EdgeDen", "IQR_NoModule", "IQR_NetModularity")
# Save median and IQR results
write.csv(median_iqr_metrics, 'Results/JPFish_Median_IQR_23_06_24.csv')
View(median_iqr_metrics)
View(all_metrics)
metrics <- colnames(all_metrics[[1]])
format_p_value <- function(p) {
if (p < 0.001) {
return("0.001")
} else if (p < 0.01) {
return("0.01")
} else if (p < 0.05) {
return("0.05")
} else {
return("non-sig")
}
}
tropical_values <- all_metrics[["Tropical"]][[metric]]
temperate_values <- all_metrics[["Temperate"]][[metric]]
# Shapiro-Wilk test for normality
shapiro_tropical <- shapiro.test(tropical_values)
shapiro_temperate <- shapiro.test(temperate_values)
# At least one group is not normally distributed, perform Mann-Whitney U test
wilcox_test <- wilcox.test(tropical_values, temperate_values)
View(wilcox_test)
# At least one group is not normally distributed, perform Mann-Whitney U test
wilcox_test <- wilcox.test(tropical_values ~ temperate_values)
View(bootstrap_metrics)
# Combine metrics from all_metrics into a single data frame with Cluster indicator
combined_metrics <- NULL
for (cluster in names(all_metrics)) {
cluster_metrics <- all_metrics[[cluster]]
cluster_df <- as.data.frame(cluster_metrics)
cluster_df$Cluster <- cluster
combined_metrics <- rbind(combined_metrics, cluster_df)
}
# Rename the columns for clarity
colnames(combined_metrics)[1:length(all_metrics[[1]])] <- colnames(all_metrics[[1]])
View(combined_metrics)
# Combine metrics from all_metrics into a single data frame with Cluster indicator
combined_metrics <- NULL
for (cluster in names(all_metrics)) {
cluster_metrics <- all_metrics[[cluster]]
cluster_df <- as.data.frame(cluster_metrics)
cluster_df$Cluster <- cluster
combined_metrics <- rbind(combined_metrics, cluster_df)
}
# Move Cluster column to the first position
combined_metrics <- combined_metrics[, c(ncol(combined_metrics), 1:(ncol(combined_metrics)-1))]
# Rename the columns for clarity
colnames(combined_metrics)[1:length(all_metrics[[1]])] <- colnames(all_metrics[[1]])
View(combined_metrics)
# Save combined metrics to CSV
write.csv(combined_metrics, 'Results/Combined_Metrics_Tropical_Temperate.csv', row.names = FALSE)
library(psych)
# Calculate mean and standard deviation for each region and metric
mean_sd_metrics <- data.frame()
for (cluster in names(all_metrics)) {
cluster_metrics <- all_metrics[[cluster]]
means <- colMeans(cluster_metrics)
sds <- apply(cluster_metrics, 2, sd)
mean_sd_metrics <- rbind(mean_sd_metrics, cbind(Cluster=cluster, t(means), t(sds)))
}
colnames(mean_sd_metrics) <- c("Cluster", "Mean_DegCents", "Mean_BetwCentr", "Mean_EigCentr", "Mean_EdgeDen", "Mean_NoModule", "Mean_NetModularity", "SD_DegCents", "SD_BetwCentr", "SD_EigCentr", "SD_EdgeDen", "SD_NoModule", "SD_NetModularity")
View(mean_sd_metrics)
# Save mean and SD results
write.csv(mean_sd_metrics, 'Results/JPFish_Mean_SD_23_06_24.csv')
# Group by Cluster and calculate metrics
metrics_summary <- combined_metrics %>%
group_by(Cluster) %>%
summarise(across(everything(), list(
Mean = mean,
SD = sd,
Median = median,
IQR = IQR
)))
View(combined_metrics)
#### Data ####
CWM <- read.csv("Data/CWM_JPFish_Biomass_TropTemp.csv")
CWM <- CWM %>% rename(Site = X)
#organise and rename
CWM <- CWM %>% relocate(Cluster, .before = Site)
CWM <- CWM %>% column_to_rownames(., var = 'Site')
colnames(CWM) <- c("Cluster", "ML_Large", "ML_Medium", "ML_Small",
"ML_V.Small", "PLD_Long", "PLD_Medium", "PLD_Short",
"PLD_V.Long", "T_Corrallivore", "T_Detritivore",
"T_Herbivore", "T_Omnivore", "T_Piscivore",
"T_Planktivore", "T_Predator", "P_Benthic",
"P_AnthozoanA", "P_Demersal",
"P_Pelagic", "P_ReefPelagic", "P_SandA", "P_SubBenthic",
"P_UpperBenthic", "R_Brooders", "R_Demersal",
"R_livebearers", "R_Nesters", "R_Scatterers")
##### Make a counter file for regions for looping:  ----
countR <- data.frame(Cluster = c("Tropical", "Temperate"))
# Initialize the result data frame
all_metrics <- list()
bootstrap_iterations <- 1000
# Bootstrapping and network metric calculation
for (i in 1:nrow(countR)) {
Cluster <- countR[i, 1]
CWM_i <- CWM[CWM$Cluster == Cluster,] %>% select(-Cluster)
# Initialize data frames to store bootstrap results
bootstrap_metrics <- data.frame(DegCents=numeric(), BetwCentr=numeric(), EigCentr=numeric(), EdgeDen=numeric(), NoModule=numeric(), NetModularity=numeric())
for (j in 1:bootstrap_iterations) {
# Bootstrapping
CWM_bootstrap <- CWM_i[sample(nrow(CWM_i), replace = TRUE), ]
# Calculate correlation matrix and significance
CWM_Cor <- rcorr(as.matrix(CWM_bootstrap))
CWM_prob <- ifelse(CWM_Cor$P < 0.05, 1, 0)
CWM_eff <- CWM_Cor$r
SignMatrix <- CWM_prob * CWM_eff
SignMatrix[is.na(SignMatrix)] <- 0
SignMatrix <- ifelse(SignMatrix > 0.1, 1, 0)
SignMatrix2 <- SignMatrix[rowSums(SignMatrix == 0) != ncol(SignMatrix), colSums(SignMatrix == 0) != nrow(SignMatrix)]
# Generate network graph
TGraph <- graph_from_adjacency_matrix(SignMatrix2, mode = "undirected")
WT_partition <- cluster_walktrap(TGraph, weights = NULL)
# Calculate network-wide metrics
DegCents <- centr_clo(TGraph, mode = "all")$centralization
BetwCentr <- centr_betw(TGraph, directed = FALSE)$centralization
EigCentr <- centr_eigen(TGraph, directed = FALSE)$centralization
EdgeDen <- edge_density(TGraph, loops = FALSE)
NoModule <- length(WT_partition)
NetModularity <- modularity(TGraph, membership(WT_partition))
# Store metrics
bootstrap_metrics[j, ] <- c(DegCents, BetwCentr, EigCentr, EdgeDen, NoModule, NetModularity)
}
# Store all bootstrap metrics for the current cluster
all_metrics[[Cluster]] <- bootstrap_metrics
}
# Combine metrics from all_metrics into a single data frame with Cluster indicator
combined_metrics <- NULL
for (cluster in names(all_metrics)) {
cluster_metrics <- all_metrics[[cluster]]
cluster_df <- as.data.frame(cluster_metrics)
cluster_df$Cluster <- cluster
combined_metrics <- rbind(combined_metrics, cluster_df)
}
# Move Cluster column to the first position
combined_metrics <- combined_metrics[, c(ncol(combined_metrics), 1:(ncol(combined_metrics)-1))]
# Rename the columns for clarity
colnames(combined_metrics)[1:length(all_metrics[[1]])] <- colnames(all_metrics[[1]])
View(combined_metrics)
View(all_metrics)
# Combine metrics from all_metrics into a single data frame with Cluster indicator
combined_metrics <- NULL
for (cluster in names(all_metrics)) {
cluster_metrics <- all_metrics[[cluster]]
cluster_df <- as.data.frame(cluster_metrics)
cluster_df$Cluster <- cluster
combined_metrics <- rbind(combined_metrics, cluster_df)
}
View(combined_metrics)
combined_metrics <- combined_metrics %>% select(Cluster, everything())
View(combined_metrics)
# Save combined metrics to CSV
write.csv(combined_metrics, 'Results/Combined_Metrics_Tropical_Temperate.csv', row.names = FALSE)
# Group by Cluster and calculate metrics
metrics_summary <- combined_metrics %>%
group_by(Cluster) %>%
summarise(across(everything(), list(
Mean = mean,
SD = sd,
Median = median,
IQR = IQR
)))
# Flatten the grouped data frame for easier viewing
metrics_summary <- as.data.frame(metrics_summary)
View(metrics_summary)
##Testing normaility
combined_metrics %>%
group_by(Cluster) %>%
do(tidy(shapiro.test(.$DegCents)))
# Define a function to test normality and store results
test_normality <- function(x) {
shapiro_test <- shapiro.test(x)
p_value <- shapiro_test$p.value
normality <- ifelse(p_value < 0.001, "< 0.001", ifelse(p_value < 0.01, "0.001 to 0.01", ifelse(p_value < 0.05, "0.01 to 0.05", "non-sig")))
return(data.frame(p_value = p_value, normality = normality))
}
# Apply Shapiro-Wilk test for normality across all metrics
normality_results <- combined_metrics %>%
summarise(across(where(is.numeric), test_normality))
View(normality_results)
hist(combined_metrics$DegCents)
hist(combined_metrics$BetwCentr)
hist(combined_metrics$)
hist(combined_metrics$NoModule)
hist(combined_metrics$NetModularity)
shapiro.test(combined_metrics$DegCents)
shapiro.test(combined_metrics$DegCents)
shapiro.test(combined_metrics$BetwCentr)
shapiro.test(combined_metrics$EigCentr)
shapiro.test(combined_metrics$EdgeDen)
shapiro.test(combined_metrics$NoModule)
shapiro.test(combined_metrics$NetModularity)
wilcox.test(DegCents ~ Cluster, data = combined_metrics, exact = F)
## Mann whitney U test
wilcox.test(NoModule ~ Cluster, data = combined_metrics, exact = F)
# Initialize an empty data frame to store results
wilcox_test_results <- data.frame(Metric = character(), W_statistic = numeric(), p_value = numeric(), stringsAsFactors = FALSE)
# Loop through each numeric metric
for (metric in colnames(combined_metrics)[sapply(combined_metrics, is.numeric)]) {
# Perform Wilcoxon rank sum test
wilcox_result <- wilcox.test(as.formula(paste(metric, "~ Cluster")), data = combined_metrics, exact = FALSE)
# Extract W statistic, p-value, and metric name
metric_name <- metric
W_statistic <- wilcox_result$statistic
p_value <- wilcox_result$p.value
# Append results to wilcox_test_results data frame
wilcox_test_results <- rbind(wilcox_test_results, data.frame(Metric = metric_name, W_statistic = W_statistic, p_value = p_value))
}
View(wilcox_test_results)
# Initialize an empty data frame to store results
wilcox_test_results <- data.frame(Metric = character(), W_statistic = numeric(), p_value = numeric(), stringsAsFactors = FALSE)
# Loop through each numeric metric
for (metric in colnames(combined_metrics)[sapply(combined_metrics, is.numeric)]) {
# Perform Wilcoxon rank sum test
wilcox_result <- wilcox.test(as.formula(paste(metric, "~ Cluster")), data = combined_metrics, exact = FALSE)
# Extract W statistic, p-value, and metric name
metric_name <- metric
W_statistic <- wilcox_result$statistic
p_value <- wilcox_result$p.value
# Round p-value to 3 decimal places
p_value <- round(p_value, digits = 3)
# Append results to wilcox_test_results data frame
wilcox_test_results <- rbind(wilcox_test_results, data.frame(Metric = metric_name, W_statistic = W_statistic, p_value = p_value))
}
View(wilcox_result)
View(wilcox_test_results)
# Save Wilcoxon test results to CSV
write.csv(wilcox_test_results, 'Results/JpFish_Wilcoxon_Test_Results.csv', row.names = FALSE)
# Save metrics summary to CSV
write.csv(metrics_summary, 'Results/JP_Fish_Metrics_Summary_Tropical_Temperate.csv', row.names = FALSE)
# Save combined metrics to CSV
write.csv(combined_metrics, 'Results/JP_FishCombined_Metrics_Tropical_Temperate.csv', row.names = FALSE)
# Save combined metrics to CSV
write.csv(combined_metrics, 'Results/JP_Fish_Combined_Metrics_Tropical_Temperate.csv', row.names = FALSE)
View(wilcox_test_results)
View(metrics_summary)
